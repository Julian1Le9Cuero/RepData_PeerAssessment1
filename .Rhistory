q(save="no")
4+5
help(package="GGally")
library(statsr)
library(dplyr)
library(ggplot2)
library(GGally)
data(evals)
dim(evals)
str(evals)
summary(evals$score)
hist(evals$score)
sum(evals$score < 3)
ggplot(data=evals, aes(x=bty_avg,y=score)) + geom_point()
sum(is.na(evals$score))
sum(is.na(evals$bty_avg))
ggplot(data=evals,aes(x=bty_avg,y=score)) + geom_jitter()
ggplot(data=evals,aes(x=bty_avg,y=score)) + geom_jitter() +
geom_smooth()
ggplot(data=evals,aes(x=bty_avg,y=score)) + geom_jitter() +
geom_smooth(method="lm")
ggplot(data=evals,aes(x=bty_avg,y=score)) + geom_jitter() +
geom_smooth(method="lm", se=FALSE)
dev.off()
ml1 <- lm(score ~ bty_avg, data=evals)
summary(ml1)
ggplot(data=ml1,aes(x=.fitted,y=.residuals)) + geom_point() +
geom_hline(yintercept = 0)
ml1
names(ml1)
ggplot(data=ml1,aes(x=.fitted,y=residuals)) + geom_point() +
geom_hline(yintercept = 0)
ggplot(data=ml1,aes(x=.fitted,y=.resid)) + geom_point() +
geom_hline(yintercept = 0,linetype="dashed") +
xlab("Fitted (predicted) values") +
ylab("Residuals")
ggplot(data=ml1,aes(x=.resid)) + geom_histogram(binwidth = 25)
ggplot(data=ml1,aes(x=.resid)) + geom_histogram()
evals %>% ggplot(aes(x=bty_f1lower, y=bty_avg)) + geom_jitter()
summarise(evals, cor(bty_f1lower, bty_avg))
ggpairs(evals,columns = 13:19)
m2_bty_gen <- lm(score ~ bty_avg + gender,data=evals)
summary(m2_bty_gen)
summary(ml1)
ggplot(m2_bty_gen, aes(x=.resid)) + geom_histogram()
ggplot(m2_bty_gen, aes(x=fitted,y=.resid)) + geom_point() +
geom_hline(yintercept = 0, linetype="dashed") +
xlab("Fitted values") +
ylab("Residuals")
ggplot(m2_bty_gen, aes(x=.fitted,y=.resid)) + geom_point() +
geom_hline(yintercept = 0, linetype="dashed") +
xlab("Fitted values") +
ylab("Residuals")
# Histogram of residuals, a little left skewed but close to 0
ggplot(m2_bty_gen, aes(x=.resid)) + geom_histogram()
ml3 <- lm(score ~ m_bty_rank, data=evals)
ml3_bty_rank <- lm(score ~ rank, data=evals)
summary(ml3_bty_rank)
levels(evals$rank)
-0.14518 < -0.12968
ml3_bty_rank <- lm(score ~ rank, data=evals)
summary(ml3_bty_rank)
ml3_bty_rank <- lm(score ~ bty_avg + rank, data=evals)
summary(ml3_bty_rank)
hyp_thet <- data.frame(gender="male", bty_avg=3)
predict(m2_bty_gen, hyp_thet)
summary(m2_bty_gen)
3.74734 + 0.07416 * 3 + 0.17239
# Prediction interval around this prediction
predict(m2_bty_gen, newprof, interval = "prediction", level = 0.95)
# Predict new value the evaluation score for a
# professor, Dr. Hypo Thetical, who is a male
# tenure track professor with an average beauty of 3.
newprof <- data.frame(gender="male", bty_avg=3)
# Prediction interval around this prediction
predict(m2_bty_gen, newprof, interval = "prediction", level = 0.95)
m4_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg
+ pic_outfit + pic_color, data = evals)
summary(m4_full)
str(m4_full)
str(evals)
summary(m4_full)
m5_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_credits + bty_avg
+ pic_outfit + pic_color, data = evals)
summary(m5_full)
m6 <- lm(score ~ ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m6)$adj.r.squared
m7 <- lm(score ~ gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m7)$adj.r.squared
m8 <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_credits
+ pic_outfit + pic_color, data = evals)
summary(m8)$adj.r.squared
m9 <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_level + cls_credits + bty_avg
+ pic_outfit + pic_color, data = evals)
summary(m9)$adj.r.squared
m10 <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_credits + bty_avg
+ pic_outfit + pic_color, data = evals)
summary(m10)$adj.r.squared
0.1634262 <  0.1623604
dev.off()
rm(list=ls())
q(ave="no")
q(save="no")
q(save="no")
?aggregate
data <- read.csv("activity/activity.csv", header=TRUE)
setwd("C:/Users/julia/OneDrive/Escritorio/RepData_PeerAssessment1")
data <- read.csv("activity/activity.csv", header=TRUE)
data_clean <- with(data, data.frame(steps=steps, date=strptime(date, format = "%Y-%m-%d"), interval=interval))
testDF <- data.frame(v1 = c(1,3,5,7,8,3,5,NA,4,5,7,9),
v2 = c(11,33,55,77,88,33,55,NA,44,55,77,99) )
by1 <- c("red", "blue", 1, 2, NA, "big", 1, 2, "red", 1, NA, 12)
by2 <- c("wet", "dry", 99, 95, NA, "damp", 95, 99, "red", 99, NA, NA)
aggregate(x = testDF, by = list(by1, by2), FUN = "mean")
aggregate(steps ~ date,data = data_clean,sum)
unique(data_clean$date)
length(unique(data$date))
## What is mean total number of steps taken per day?
# Calculate the total number of steps taken per day
b=aggregate(steps ~ date,data = data_clean,sum)
## What is mean total number of steps taken per day?
# Calculate the total number of steps taken per day
c=aggregate(steps ~ date,data = data,sum)
library(dplyr)
c = data_clean %>% group_by(date) %>% summarise(total=sum(steps))
c
heaD(b)
head(b)
head(b,8)
c = data_clean %>% group_by(date) %>% summarise(total=sum(steps,na.rm=T))
c
sum(c$total == 0)
## What is mean total number of steps taken per day?
# Calculate the total number of steps taken per day
b=aggregate(steps ~ date,data = data_clean,sum,na.action = 0)
d=aggregate(steps ~ date,data = data_clean,FUN=function(x){ifelse(is.na(x),0,sum(x))})
head(d)
d=aggregate(steps ~ date,data = data_clean,FUN=function(x){ifelse(length(x)==1,0,sum(x))})
head(d,2)
data_clean %>% group_by(date) %>% summarise(total=sum(steps,na.rm=T))
data_clean %>% group_by(as.factor(date)) %>% summarise(total=sum(steps,na.rm=T))
data_clean %>% group_by(date=as.factor(date)) %>% summarise(total=sum(steps,na.rm=T))
length(unique(data$date))
g = aggregate(steps ~ date, data=data_clean,count)
barplot(data_clean$date)
data_clean %>% group_by(date=as.factor(date)) %>% summarise(total=n())
e=data_clean %>% group_by(date=as.factor(date)) %>% summarise(total=n())
tail(e)
hist(data$steps)
unique(e$total)
data_clean %>% group_by(date=as.factor(date)) %>% summarise(total=sum(steps,na.rm=T))
hist(data_clean$date,main="Number of steps taken each day")
hist(data_clean$steps,main="Number of steps taken each day", xlab = "Steps")
data_clean %>% group_by(date=as.factor(date)) %>% summarise(total=n())
data_clean %>% group_by(date=as.factor(date)) %>% summarise(total=sum(steps,na.rm=T)) %>%
summarise(mean=mean(total),median=median(total))
heaD(c)
head(c)
mean(c$total)
median(c$total)
head(data_clean$interval,10)
length(unique(data_clean$interval))
step_inter <- aggregate(steps ~ interval, data=data_clean,FUN=mean)
head(step_inter)
data_clean %>% group_by(interval) %>% summarise(mean=mean(steps))
data_clean %>% group_by(interval) %>% summarise(mean=mean(steps,na.rm=T))
head(step_inter)
with(step_inter, plot(x=interval, y=steps,type="l", main = "Average number of steps taken by interval"))
subset(step_inter, steps==max(step_inter$steps))
subset(step_inter, steps==max(step_inter$steps))$interval
?sort
sort(step_inter$steps,decreasing = T)[1:5]
sum(is.na(data$date))
sum(is.na(data$steps))
sum(is.na(data$interval))
nrow(data[!complete.cases(data),])
nrow(data_clean[!complete.cases(data_clean),])
mean(data$steps)
mean(data$steps,na.rm=T)
head(data_clean)
new <- mutate(data_clean, steps=ifelse(!is.na(steps), steps, mean(steps,na.rm=TRUE)))
head(new)
nrow(new[!complete.cases(new),])
new_data <- mutate(data_clean, steps=ifelse(!is.na(steps), steps, mean(steps,na.rm=TRUE)))
tail(new_data$steps)
new_data$steps[5000:5020]
data$steps[5000:5020]
hist(data_clean$steps)
rm(list=ls())
setwd("C:/Users/julia/OneDrive/Escritorio/RepData_PeerAssessment1")
library(dplyr)
## Loading and preprocessing the data
raw_data <- read.csv("activity/activity.csv", header=TRUE)
# Transform date column
new_data <- with(raw_data, data.frame(steps=steps, date=strptime(date, format = "%Y-%m-%d"), interval=interval))
## What is mean total number of steps taken per day?
# Total number of steps taken per day
new_data %>% group_by(date=as.factor(date)) %>% summarise(total=sum(steps,na.rm=T))
# Histogram
# of the total number of steps taken each day
hist(new_data$steps,main="Number of steps taken each day", xlab = "Steps")
# Mean and median
# of the total number of steps taken per day
new_data %>% group_by(date=as.factor(date)) %>% summarise(total=sum(steps,na.rm=T)) %>%
summarise(mean=mean(total),median=median(total))
## What is the average daily activity pattern?
# Time series plot of the 5-minute
# interval and the average number of
# steps taken, averaged across all days
step_inter <- aggregate(steps ~ interval, data=new_data,FUN=mean)
with(step_inter, plot(x=interval, y=steps,type="l", main = "Average number of steps taken by interval"))
# The 5-minute interval that contains the maximum
# number of steps across is the one with id 835
subset(step_inter, steps==max(step_inter$steps))$interval
## Imputing missing values
# Total number of missing values in the dataset
nrow(raw_data[!complete.cases(raw_data),])
# Filling in all missing values in the dataset with average steps
# Created new dataset
data_clean <- mutate(new_data, steps=ifelse(!is.na(steps), steps, mean(steps,na.rm=TRUE)))
# Make a histogram of the total number of steps
# taken each day and Calculate and report the mean
# and median total number of steps taken per day.
# Do these values differ from the estimates from
# the first part of the assignment? What is the
# impact of imputing missing data on the estimates
# of the total daily number of steps?
hist(data_clean$steps)
## Are there differences in activity patterns between weekdays and weekends?
# For this part the weekdays() function may be of
# some help here. Use the dataset with the filled-in
# missing values for this part.
#
# Create a new factor variable in the dataset with
# two levels – “weekday” and “weekend” indicating
# whether a given date is a weekday or weekend day.
# Make a panel plot containing a time series plot
# (i.e. type = "l") of the 5-minute interval (x-axis)
# and the average number of steps taken, averaged
# across all weekday days or weekend days (y-axis).
# See the README file in the GitHub repository to see
# an example of what this plot should look like using
# simulated data.
hist(new_data$steps)
hist(data_clean$steps)
weekdays("2010-11-12")
data_clean %>% group_by(date=as.factor(date)) %>% summarise(total_steps=sum(steps))
new_data %>% group_by(date=as.factor(date)) %>% summarise(total_steps=sum(steps,na.rm=T)) %>%
summarise(mean=mean(total_steps),median=median(total_steps))
data_clean %>% group_by(date=as.factor(date)) %>% summarise(total_steps=sum(steps)) %>%
summarise(mean=mean(total_steps),median=(median(total_steps)))
hist(new_data$steps,main="Number of steps taken each day", xlab = "Steps")
hist(data_clean$steps)
par(mfrow=c(1,2))
hist(new_data$steps,main="Number of steps taken each day", xlab = "Steps")
hist(data_clean$steps)
dev.off()
hist(data_clean$steps)
hist(new_data$steps,main="Number of steps taken each day", xlab = "Steps")
str(data_clean)
sm <- data_clean$date[1]
sm
weekdays(sm)
unique(weekdays(data_clean$date))
u = c("martes",    "miércoles", "jueves")
u
"martes" %>% u
"martes" %in% u
data_clean <- mutate(data_clean,weekday_type=ifelse(weekdays(date) %in% c("sábado", "domingo"), "weekend", "weekday"))
head(data_clean)
data_clean[5000:5010,]
unique(data_clean$weekday_type)
b <- subset(data_clean, weekday_type=="weekend")
weekdays(b$date[1:6])
b$date[1:6]
help(package="lattice")
head(step_inter)
library(lattice)
xyplot(steps ~ interval|mean(steps),data=data_clean,
group=weekday_type,
type="o")
xyplot(steps ~ interval|mean(steps),data=data_clean,
group=weekday_type,
type="l")
xyplot(steps ~ interval|mean(steps),data=data_clean,
group=weekday_type,
type="l", panel=panel.smoother)
?xyplot
xyplot(steps ~ interval|mean(steps),data=data_clean,
group=weekday_type,
type="l", panel="panel.superpose")
xyplot(steps ~ interval|mean(steps),data=new_data,
type="l", panel="panel.superpose")
xyplot(steps ~ interval|mean(steps),data=new_data,
type="l")
xyplot(steps ~ interval|mean(steps),data=new_data,
group=weekday_type,
type="l")
xyplot(steps ~ interval|mean(steps),data=new_data,
group=interval,
type="l")
xyplot(mean(steps) ~ interval|weekday_type,data=new_data,
type="l")
xyplot(mean(steps) ~ interval|weekday_type,data=data_clean,
type="l")
xyplot(steps ~ interval|weekday_type,data=data_clean,
type="l")
data_clean %>% group_by(interval) %>% summarise(date=date,avg_steps=mean(steps),weekday_type=weekday_type)
data_clean %>% group_by(interval) %>% summarise(avg_steps=mean(steps))
xyplot(steps ~ interval|weekday_type,data=data_clean,
type="l",panel=function(x,y,...){
panel.xyplot(x,mean(y),...)
})
library(swirl)
?panel.average
?panel.xyplot
swirl()
head(airquality)
xyplot(Ozone~Wind,ddata = airquality)
xyplot(Ozone~Wind,data = airquality)
xyplot(Ozone~Wind,data = airquality,col="red",pch=8,main="Big Apple Data")
xyplot(Ozone ~ Wind, data = airquality, pch=8,
col="red", main="Big Apple Data")
xyplot(Ozone~Wind|as.factor(Month),data=airquality)
xyplot(Ozone~Wind|as.factor(Month),data=airquality,layout=c(5,1))
xyplot(Ozone~Wind|Month,data=airquality,layout=c(5,1))
p <- xyplot(Ozone~Wind,data=airquality)
p
names(p)
mynames[myfull]
p[["formula"]]
p[["x.limits"]]
table(f)
xyplot(y~x|f,layout=c(2,1))
v1
v2
myedit("plot1.R")
source("plot1.R",local=TRUE)
source(pathtofile="plot1.R",local=TRUE)
source(pathtofile("plot1.R"),local=TRUE)
myedit("plot2.R")
source(pathtofile("plot2.R"),local=TRUE)
str(diamonds)
table(diamonds$color)
table(diamonds$color,diamonds$cut)
myedit("myLabels.R")
source(pathtofile("myLabels.R"),local=TRUE)
xyplot(price~carat|color*cut,data=diamonds,strip=FALSE,pch=20,xlab=myxlab,ylab = myylab,main=mymain)
xyplot(price~carat|color*cut,data=diamonds,pch=20,xlab=myxlab,ylab = myylab,main=mymain)
dev.off()
xyplot(steps ~ interval|weekday_type,data=data_clean,
type="l", layout=c(1,2),panel=function(x,y,...){
panel.xyplot(x,mean(y),...)
})
xyplot(steps ~ interval|weekday_type,data=data_clean,
type="l", layout=c(1,2))
xyplot(steps ~ interval,data=new_data,
type="l")
xyplot(mean(steps) ~ interval,data=new_data,
type="l")
xyplot(steps ~ interval,data=new_data,
type="l", panel=function(x,y,...){
panel.xyplot(x,mean(y))
})
xyplot(steps ~ interval,data=new_data,
type="l", panel=function(x,y,...){
panel.xyplot(x,y)
panel.average(x,y,fun=mean)
})
xyplot(steps ~ interval,data=new_data,
type="l", panel=function(x,y,...){
panel.xyplot(x,y)
panel.average(x,y,fun=mean,type="l")
})
with(step_inter, plot(x=interval, y=steps,type="l", main = "Average number of steps taken by interval"))
?summarise_all
xyplot(steps ~ interval|weekday_type,data=data_clean,
type="l", layout=c(1,2))
?xyplot
library(ggplot)
library(ggplot2)
data_clean %>% ggplot(aes(x=interval,y=mean(steps))) + geom_line()
data_clean %>% ggplot(aes(x=interval,y=steps)) + geom_line() + facet_grid(~weekday_type)
?geom_line
new_data %>% ggplot(aes(x=interval,y=stat(mean(steps)))) + geom_line()
new_data %>% ggplot(aes(x=interval,y=steps)) + stat_summary(fun.y = "mean",geom="line")
new_data %>% ggplot(aes(x=interval,y=steps)) + stat_summary(fun = "mean",geom="line")
with(step_inter, plot(x=interval, y=steps,type="l", main = "Average number of steps taken by interval"))
data_clean %>% ggplot(aes(x=interval,y=steps)) + stat_summary(fun = "mean", geom="line") + facet_grid(~weekday_type)
rm(list=ls())
dev.off()
q(save="no")
